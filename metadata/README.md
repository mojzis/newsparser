# Parquet File Metadata Documentation

This directory contains detailed documentation for the parquet files generated by the Bluesky MCP Monitor project.

## Overview

The project uses a stage-based processing pipeline that generates parquet files at each stage for analytics purposes. As of the latest update, parquet files are organized by run date and contain the last 7 days of data in each file.

## Available Formats

### Markdown Documentation (Human-Readable)
- Comprehensive documentation with examples and usage notes
- Detailed explanations of data relationships and processing

### JSON Schemas (Machine-Readable)
- Structured metadata for programmatic access
- Designed for integration with web interfaces and tools
- Includes type information, categories, and constraints

## File Organization

```
parquet/
├── collect/
│   └── by-run-date/
│       └── {YYYY-MM-DD}_last_7_days.parquet
├── fetch/
│   └── by-run-date/
│       └── {YYYY-MM-DD}_last_7_days.parquet
└── evaluate/
    └── by-run-date/
        └── {YYYY-MM-DD}_last_7_days.parquet
```

## Stage Documentation

- **[collect_parquet.md](./collect_parquet.md)** - Bluesky posts matching search criteria
- **[fetch_parquet.md](./fetch_parquet.md)** - Results from fetching URLs found in posts
- **[evaluate_parquet.md](./evaluate_parquet.md)** - AI evaluations of fetched articles

## Data Flow

1. **Collect Stage**: Gathers posts from Bluesky based on search configurations
2. **Fetch Stage**: Extracts and fetches unique URLs from collected posts
3. **Evaluate Stage**: Analyzes fetched content using AI for relevance and classification

## Key Features

- **7-Day Rolling Window**: Each parquet file contains the last 7 days of data
- **Daily Generation**: New files are created daily with updated data
- **Stage Isolation**: Each stage has its own parquet structure and schema
- **Analytics-Optimized**: Columnar format with type optimization for efficient querying

## Usage

These parquet files are designed for:
- Historical analysis of collected data
- Trend analysis over time
- Content quality metrics
- Engagement analysis
- URL and domain analysis

## JSON Schema Files

- **[collect.json](./collect.json)** - Schema for Bluesky posts data
- **[fetch.json](./fetch.json)** - Schema for URL fetch results
- **[evaluate.json](./evaluate.json)** - Schema for AI evaluation results
- **[schema.json](./schema.json)** - Master schema with project overview
- **[example.html](../src/html/metadata-example.html)** - Interactive schema viewer example

## Technical Notes

- Files use Snappy compression for efficient storage
- Datetime fields are stored with microsecond precision
- Lists are stored as native Parquet arrays
- String fields with low cardinality are optimized as categories
- All timestamps are in UTC

## Using JSON Schemas

The JSON schemas can be loaded in JavaScript for dynamic interfaces:

```javascript
// Load schema
const response = await fetch('/metadata/collect.json');
const schema = await response.json();

// Access column definitions
schema.columns.forEach(col => {
    console.log(`${col.name}: ${col.type} - ${col.description}`);
});
```